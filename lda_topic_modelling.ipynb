{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/przemyslaw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/przemyslaw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/przemyslaw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# To download necessary resources:\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv(os.path.join('data', 'writers.stackexchange.com', 'Posts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    text = re.sub(cleanr, '', text)\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\\\\", \"\")\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = clean_html(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    word_list = word_tokenize(text)\n",
    "    word_list = [word.strip() for word in word_list if not all(letter in string.punctuation for letter in word)]\n",
    "    word_list = [\"<NUM>\" if word.isdigit() else word for word in word_list]\n",
    "    \n",
    "    return \" \".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i 've always wanted to start writing in a totally amateur way but whenever i want to start something i instantly get blocked having a lot of questions and doubts are there some resources on how to start becoming a writer i 'm thinking something with tips and easy exercises to get the ball rolling\",\n",
       " 'what kind of story is better suited for each point of view are there advantages or disadvantages inherent to them for example writing in the first person you are always following a character while in the third person you can jump between story lines']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = posts.Body[posts.Body.notna()]\n",
    "texts = [clean_text(body) for body in texts]  # takes a few minuts to complete\n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32130x1318 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1462719 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.3, min_df=0.01, stop_words=list(stopwords.words('english')))\n",
    "cv_X = cv.fit_transform(texts)\n",
    "cv_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak czytamy w dokumentacji (http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "\n",
    "Convert a collection of text documents to a matrix of token counts\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "\n",
    "Przyjmuje ciąg stringów i metodą fit_transform zwraca macierz wystąpień poszczególnych tokenów.\n",
    "\n",
    "max_df - część najczęściej występujących wyrazów, które chcemy wyciąć\n",
    "\n",
    "min_df - część najrzadziej występujących wyrazów, które chcemy wyciąć\n",
    "\n",
    "stopwords - lista stopwordów, które chcemy ignorować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>character</td>\n",
       "      <td>20201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>num</td>\n",
       "      <td>16017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>write</td>\n",
       "      <td>14389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>book</td>\n",
       "      <td>14142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>want</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>make</td>\n",
       "      <td>13789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>use</td>\n",
       "      <td>13323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>people</td>\n",
       "      <td>13224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>characters</td>\n",
       "      <td>12629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>reader</td>\n",
       "      <td>12404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "161    character  20201\n",
       "774          num  16017\n",
       "1305       write  14389\n",
       "123         book  14142\n",
       "1261        want  13800\n",
       "674         make  13789\n",
       "1240         use  13323\n",
       "827       people  13224\n",
       "162   characters  12629\n",
       "924       reader  12404"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame({\n",
    "    'word': cv.get_feature_names(),\n",
    "    'count': cv_X.toarray().sum(axis=0)\n",
    "})\n",
    "counts.nlargest(10, columns='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "Latent Dirichlet Allocation with online variational Bayes algorithm (http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n",
    "\n",
    "Metoda ta służy do określania tematów dokumentów tekstowych w nienadzorowany sposób. Określamy na ile tematów chcemy podzielić nasz zbiór tesktów, a algorytm wykrywa te tematy poprzez podanie listy słów do niego pasujących. Więcej można poczytać o nim na Wikipedii: https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "\n",
    "n_componenets - liczba tematów, które chcemy przyporządkować danym\n",
    "\n",
    "max_iter - maksymalna liczba iteracji (żeby się za długo nie liczyło)\n",
    "\n",
    "learning_method - 'batch' lub 'online' (używane tylko w metodzie fit). Online jest szybsza, batch używa wszystkich danych treningowych w każdej iteracji EM do zaktualizowania components_.\n",
    "\n",
    "Na obiekcie lda po wywołaniu metody fit będziemy mogli zobaczyć lda.components_, czyli tablicę wymiaru \\[n_components, n_features\\], gdzie element (i,j) reprezentuje jak często słowo j jest przypisywane do tematu i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=3, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=123, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 3\n",
    "lda = LatentDirichletAllocation(n_components = n_components, max_iter=5, learning_method='online', random_state=123)\n",
    "lda.fit(cv_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = 'Topic #%d: ' % topic_idx\n",
    "        message += ' '.join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message + \"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: write book work get read people good want time know find make books num think first something need way even writer go much many also well may writers really reading try lot might novel idea could ideas things better best written start take fiction going help say see someone published\n",
      "\n",
      "Topic #1: character characters reader make way something people think person world could know want even first plot time things scene example good might need point much life readers also different may protagonist main two see get say real feel going really show stories well end tell without another thing hero said\n",
      "\n",
      "Topic #2: num use name word using text words used example style page also book different sentence information source author may question chapter copyright work technical two language case paragraph need could names title first want number way might version software many etc questions specific pages line document original reference content article\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, cv.get_feature_names(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mozna poeksperymentować z liczbą topiców. Dla n_components=3 widzimy, że zerowy temat dotyczy głównie ludzi, którzy chcą zająć się pisaniem i publikować swoje opowieści, pierwszy dotyczy bardziej książek i ich treści natomiast drugi jest bardziej techniczny. \n",
    "\n",
    "Możemy też podejrzeć posty należące do tych tematów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96725055, 0.01685198, 0.01589747],\n",
       "       [0.02627304, 0.94285227, 0.03087469],\n",
       "       [0.90816841, 0.04653362, 0.04529797],\n",
       "       [0.35094893, 0.63207076, 0.01698031],\n",
       "       [0.93456541, 0.03324022, 0.03219437],\n",
       "       [0.40615141, 0.04473548, 0.54911311],\n",
       "       [0.44400595, 0.18601468, 0.36997937],\n",
       "       [0.13195231, 0.858124  , 0.00992368],\n",
       "       [0.84231466, 0.08622382, 0.07146152],\n",
       "       [0.7150574 , 0.14220697, 0.14273563]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_features = lda.transform(cv_X[:10, ])\n",
    "lda_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = np.argmax(lda_features, axis=1)\n",
    "body_cleaned = [clean_html(body) for body in posts.Body[posts.Body.notna()].values]\n",
    "posts_topics = pd.DataFrame({\"posts\": body_cleaned[:10], \"topics\":topics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've always wanted to start writing (in a tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What kind of story is better suited for each p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I finished my novel, and everyone I've talked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When writing a short-story to highlight a cert...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I keep hearing about literary fiction, and how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BeginningWriters.com has some good articles fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whenever I attempt to write something, I do it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you have a point that you do want to convey...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I heard a writer talking about pantsing a stor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In the sense you mean, it probably stands for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  topics\n",
       "0  I've always wanted to start writing (in a tota...       0\n",
       "1  What kind of story is better suited for each p...       1\n",
       "2  I finished my novel, and everyone I've talked ...       0\n",
       "3  When writing a short-story to highlight a cert...       1\n",
       "4  I keep hearing about literary fiction, and how...       0\n",
       "5  BeginningWriters.com has some good articles fo...       2\n",
       "6  Whenever I attempt to write something, I do it...       0\n",
       "7  If you have a point that you do want to convey...       1\n",
       "8  I heard a writer talking about pantsing a stor...       0\n",
       "9  In the sense you mean, it probably stands for ...       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
